{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f308e7e8-2e97-4af5-8b75-972cce9337a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlinsights.mlmodel import PiecewiseRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "from helpers.pwl_tree import get_coef, get_subdomain, y_min_max_calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a024c6-234d-4a2b-8521-c5d104893d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best models\n",
    "import pickle\n",
    "with open('./results/pwl_best_models.pickle', 'rb') as best_models_pickle:\n",
    "    best_models = pickle.load(best_models_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e3d582-2d8a-4d4b-80d4-fbe4207c5e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_max = 5 # max dimention of the input vector\n",
    "n_samples = 10 # number of sampled quadratic function for each dimension\n",
    "\n",
    "times_n = {} # dict that stores solution times\n",
    "objs_n = {} # dict that stores obj function values\n",
    "num_binvars_n = {} # dict that stores # binary variables\n",
    "num_constrs_n = {} # dict that stores # constraints\n",
    "\n",
    "# set random seed\n",
    "global_seed = 777\n",
    "random.seed(global_seed)\n",
    "np.random.seed(global_seed)\n",
    "seeds = np.random.randint(1,1000,(1,n_samples))[0]\n",
    "print(seeds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f9d42b-7b00-461f-b8f5-3d833323eeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in tqdm(range(1, n_max + 1)):\n",
    "\n",
    "    times = []\n",
    "    objs = []\n",
    "    num_binvars = []\n",
    "    num_constrs = []\n",
    "    for n_sample in range(n_samples):\n",
    "    \n",
    "        # data reading\n",
    "        random.seed(seeds[n_sample])\n",
    "        np.random.seed(seeds[n_sample])\n",
    "        filename = './' + str(n) + '_' + str(n_sample) + '_train.csv'\n",
    "        df = pd.read_csv(filename)\n",
    "        \n",
    "        X_train_raw = df.iloc[:, 0:-1].values\n",
    "        y_train_raw = df.iloc[:, -1].values\n",
    "        \n",
    "        # scaling\n",
    "        sc_X = MinMaxScaler()\n",
    "        sc_y = MinMaxScaler()\n",
    "\n",
    "        X_variable = sc_X.fit_transform(X_train_raw)\n",
    "        Y_variable = sc_y.fit_transform(y_train_raw.reshape(-1,1))\n",
    "        Y_variable = np.squeeze(y_train_raw)\n",
    "        \n",
    "        # continue to scaling for obtain parameters for subdomains\n",
    "        dx = sc_X.data_range_\n",
    "        dy = sc_y.data_range_\n",
    "        xmin = sc_X.data_min_\n",
    "        ymin = sc_y.data_min_\n",
    "    \n",
    "        # set random seed\n",
    "        random.seed(global_seed)\n",
    "        np.random.seed(global_seed)\n",
    "        \n",
    "        # use the model trained via quadratic_model_training.ipynb\n",
    "        best_tree = best_models[n][n_sample]\n",
    "        \n",
    "        # obtain queries corresponding to non-leaf node, as well as leaf node information\n",
    "        # revert the scaling of prediction at each leaf node\n",
    "        y_train_predict = np.transpose(sc_y.inverse_transform(best_tree.predict(X_variable).reshape(-1,1))).tolist()[0]\n",
    "        # ymin_in_bins (ymax_in_bins) contains min/max predicted y values for each leaf\n",
    "        ymin_in_bins, ymax_in_bins = y_min_max_calc(best_tree, X_variable, y_train_predict)\n",
    "        \n",
    "        # linear regression model for each leaf node\n",
    "        lincoeff = get_coef(best_tree)\n",
    "        # obtain subdomain information for each leaf node; cannot directly obtain it from the PiecewiseRegressor using this version of mlinsights;\n",
    "        # Train the decision tree to obtain the binner used by the PiecewiseRegressor\n",
    "        dctree = DecisionTreeRegressor(random_state=0,min_samples_leaf=best_tree.binner.min_samples_leaf)\n",
    "        dctree.fit(X_variable, Y_variable)\n",
    "        # obtain tree structure information\n",
    "        tree_dict, tree_params = get_subdomain(dctree, n)\n",
    "        \n",
    "        # tree_params_less: upper bound of x for a leaf\n",
    "        # tree_params_larger: lower bound of x for a leaf\n",
    "        tree_params_less = tree_params[:,:n]\n",
    "        tree_params_larger = tree_params[:,n:]\n",
    "        # number of leaves\n",
    "        n_leaves = best_tree.n_estimators_\n",
    "        \n",
    "        # inverse transform coefficients and intercepts of linear regressors of each leaf\n",
    "        lincoeff_coeffs_raw = lincoeff[:,:-1]\n",
    "        lincoeff_intecept_raw = lincoeff[:,-1]\n",
    "        \n",
    "        lincoeff_coeffs = lincoeff_coeffs_raw\n",
    "        lincoeff_intecept = lincoeff_intecept_raw\n",
    "    \n",
    "        lincoeff_coeffs = lincoeff_coeffs_raw * dy\n",
    "        lincoeff_coeffs = np.divide(lincoeff_coeffs,dx)\n",
    "        lincoeff_intecept = lincoeff_intecept_raw - np.sum(np.divide(np.multiply(lincoeff_coeffs_raw, xmin), dx), axis=1)\n",
    "        lincoeff_intecept *= dy\n",
    "        lincoeff_intecept += ymin\n",
    "        \n",
    "        # revert scaling of tree params\n",
    "        tree_params_less = sc_X.inverse_transform(tree_params_less)\n",
    "        tree_params_larger = sc_X.inverse_transform(tree_params_larger)\n",
    "        \n",
    "        # set generation\n",
    "        # set for each input variable dimension\n",
    "        rangen = range(n)\n",
    "        # set for leaf nodes\n",
    "        rangen_leaves = range(n_leaves)\n",
    "        # (u, m) tuple in the paper\n",
    "        rangeleaven = []\n",
    "        for i in rangen:\n",
    "            for j in rangen_leaves:\n",
    "                rangeleaven.append((i,j))\n",
    "        # set containing (m, k) tuple for constraints for truncation\n",
    "        rangemk = []\n",
    "        rangek = range(3)\n",
    "        for i in rangen_leaves:\n",
    "            for j in rangek:\n",
    "                rangemk.append((i,j))\n",
    "            \n",
    "        #create a new model\n",
    "        m = gp.Model(\"PWL\")\n",
    "        m.Params.LogToConsole = 0\n",
    "\n",
    "        # input variable bound\n",
    "        x_ub = [2] * n\n",
    "        x_lb = [-2] * n\n",
    "        \n",
    "        # create variables\n",
    "        # binary variable Z_m\n",
    "        z = m.addVars(rangen_leaves, name = 'z', vtype = GRB.BINARY)\n",
    "        # independent variable X_u\n",
    "        x = m.addVars(rangen, ub = x_ub, lb = x_lb, name = 'x')\n",
    "        # disaggregate variable \\bar{X}_{u, m}\n",
    "        x_bar = m.addVars(rangeleaven, lb = -float('inf'), name = 'x_bar')\n",
    "        # disaggregate variable \\bar{Y}_m\n",
    "        y_bar = m.addVars(rangen_leaves, name = 'y_bar', lb = -float('inf'))\n",
    "        # dependent variable Y\n",
    "        y = m.addVar(obj = 1, name = 'y', lb = -float('inf'))\n",
    "        # disaggregate variable \\tilde{Y}_{m, k}\n",
    "        y_tilde = m.addVars(rangemk, name = 'y_tilde', lb = -float('inf'))\n",
    "        # binary disaggregate variable \\bar{Z}_{m, k}\n",
    "        w = m.addVars(rangemk, name = 'w', vtype = GRB.BINARY)\n",
    "        # disaggregate variable \\hat{Y}\n",
    "        y_hat = m.addVars(rangen_leaves, name = 'y_hat', lb = -float('inf'))\n",
    "        \n",
    "        # obj\n",
    "        m.setObjective(y, GRB.MINIMIZE)\n",
    "\n",
    "        # Add constraint\n",
    "        # Constraint 3B-1\n",
    "        m.addConstr((gp.quicksum(z[l] for l in rangen_leaves) == 1), name = 'onez')\n",
    "        \n",
    "        # Constraint 3B-2\n",
    "        m.addConstrs((tree_params_larger[l][k] * z[l] <= x_bar[k,l] for k,l in rangeleaven), name = 'largerthan')\n",
    "        m.addConstrs((tree_params_less[l][k] * z[l] >= x_bar[k,l] for k,l in rangeleaven), name = 'lessthan')\n",
    "        \n",
    "        # Constraint 3B-3\n",
    "        m.addConstrs((gp.quicksum(x_bar[k,l] for l in rangen_leaves) == x[k] for k in rangen), name = 'calcx') \n",
    "        \n",
    "        # Constraint 3B-4\n",
    "        m.addConstr((gp.quicksum(y_bar[l] for l in rangen_leaves) == y), name = 'calcy')\n",
    "        \n",
    "        # Constraint 3B-5\n",
    "        m.addConstrs((gp.quicksum(lincoeff_coeffs[l][k] * x_bar[k,l] for k in rangen) + lincoeff_intecept[l] * z[l] == y_hat[l] \\\n",
    "                  for l in rangen_leaves), name = 'calcy_hat')\n",
    "        \n",
    "        # Constraint 3B-6\n",
    "        m.addConstrs((y_bar[l] == ymax_in_bins[l] * w[l,0] + y_tilde[l, 1] + ymax_in_bins[l] * w[l,2] for l in rangen_leaves),\n",
    "                     name = 'calcy_bar')\n",
    "        \n",
    "        # Constraint 3B-7\n",
    "        m.addConstrs((gp.quicksum(y_tilde[l,k] for k in rangek) == y_hat[l] for l in rangen_leaves), name = 'calcy_hat1')\n",
    "        \n",
    "        # Constraint 3B-8\n",
    "        m.addConstrs((gp.quicksum(w[l,k] for k in rangek) == z[l] for l in rangen_leaves), name = 'calcw')\n",
    "        \n",
    "        # Constraint 3B-9\n",
    "        m.addConstrs((y_tilde[l, 0] <= ymin_in_bins[l] * w[l,0] for l in rangen_leaves), name = 'calcy_tilde0')\n",
    "        \n",
    "        # Constraint 3B-10\n",
    "        m.addConstrs((y_tilde[l, 1] >= ymin_in_bins[l] * w[l,1] for l in rangen_leaves), name = 'calcy_tilde1')\n",
    "        m.addConstrs((y_tilde[l, 1] <= ymax_in_bins[l] * w[l,1] for l in rangen_leaves), name = 'calcy_tilde11')\n",
    "        \n",
    "        # Constraint 3B-11\n",
    "        m.addConstrs((y_tilde[l, 2] >= ymax_in_bins[l] * w[l,2] for l in rangen_leaves), name = 'calcy_tilde2')\n",
    "        \n",
    "        m.update()\n",
    "        m.write(\"m.lp\")\n",
    "        \n",
    "        # start optimization\n",
    "        m.optimize()\n",
    "        \n",
    "        times.append(m.Runtime)\n",
    "        objs.append(m.objVal)\n",
    "        num_binvars.append(m.NumBinVars)\n",
    "        num_constrs.append(m.NumConstrs)\n",
    "    \n",
    "    times_n[n] = times\n",
    "    objs_n[n] = objs\n",
    "    num_binvars_n[n] = num_binvars\n",
    "    num_constrs_n[n] = num_constrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d400553-47eb-4a9d-a713-6731d1471636",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(times_n)\n",
    "print(objs_n)\n",
    "print(num_binvars_n)\n",
    "print(num_constrs_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8810839e-6dac-4ee1-b63b-37464c0e8fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_save(path, file, filename):\n",
    "    file_loc = path + '/' + filename + '.pickle'\n",
    "    with open(file_loc, 'wb') as handle:\n",
    "        pickle.dump(file, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# create the directory to save the results\n",
    "path = './results_opt_pwl'\n",
    "\n",
    "try:\n",
    "    os.mkdir(path)\n",
    "except FileExistsError:\n",
    "    print('Folder already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b47bda-5a53-416a-8516-16f230043be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_save(path, objs_n, 'pwl_objs_n')\n",
    "pickle_save(path, times_n, 'pwl_times_n')\n",
    "pickle_save(path, num_binvars_n, 'pwl_binvars_n')\n",
    "pickle_save(path, num_constrs_n, 'pwl_constrs_n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
