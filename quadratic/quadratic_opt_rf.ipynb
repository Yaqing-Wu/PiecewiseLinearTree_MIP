{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44904cb-ba69-4706-858d-bd016c928219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "from helpers.rf import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc68ad9-c87f-40c0-8ecd-e10a24a5ed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best models\n",
    "with open('./results/rf_best_models.pickle', 'rb') as best_models_pickle:\n",
    "    best_models = pickle.load(best_models_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35697f8f-0408-41b0-a92e-46064069d465",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_max = 5 # max dimention of the input vector\n",
    "n_samples = 10 # number of sampled quadratic function for each dimension\n",
    "\n",
    "times_n = {} # dict that stores solution times\n",
    "objs_n = {} # dict that stores obj function values\n",
    "num_binvars_n = {} # dict that stores # binary variables\n",
    "num_constrs_n = {} # dict that stores # constraints\n",
    "\n",
    "# set random seed\n",
    "global_seed = 777\n",
    "random.seed(global_seed)\n",
    "np.random.seed(global_seed)\n",
    "seeds = np.random.randint(1,1000,(1,n_samples))[0]\n",
    "print(seeds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabbadc5-9c82-4d49-8c33-8bf97ae21a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in tqdm(range(1, n_max+1)):\n",
    "\n",
    "    times = []\n",
    "    objs = []\n",
    "    num_binvars = []\n",
    "    num_constrs = []\n",
    "    for n_sample in tqdm(range(n_samples)):\n",
    "    \n",
    "        # data reading\n",
    "        random.seed(seeds[n_sample])\n",
    "        np.random.seed(seeds[n_sample])\n",
    "        filename = './' + str(n) + '_' + str(n_sample) + '_train.csv'\n",
    "        df = pd.read_csv(filename)\n",
    "        \n",
    "        X_variable_raw = df.iloc[:, 0:-1].values\n",
    "        Y_variable_raw = df.iloc[:, -1].values\n",
    "        \n",
    "        # scaling\n",
    "        sc_X = MinMaxScaler()\n",
    "        sc_y = MinMaxScaler()\n",
    "\n",
    "        X_variable = sc_X.fit_transform(X_variable_raw)\n",
    "        Y_variable = sc_y.fit_transform(Y_variable_raw.reshape(-1,1))\n",
    "        Y_variable = np.squeeze(Y_variable)\n",
    "        \n",
    "        # set random seed\n",
    "        random.seed(global_seed)\n",
    "        np.random.seed(global_seed)\n",
    "    \n",
    "        # use the model trained via quadratic_model_training.ipynb\n",
    "        rf = best_models[n][n_sample]\n",
    "        Y_predict = rf.predict(X_variable)\n",
    "    \n",
    "        # extract model parameters\n",
    "        flag=1 #regression tree\n",
    "        # equal weighted trees\n",
    "        weight_all = 1/rf.n_estimators\n",
    "        # get a list of trees\n",
    "        trees=get_input(rf)\n",
    "        ntrees = len(trees)\n",
    "        # indices of all the trees\n",
    "        settrees = range(ntrees)\n",
    "        # p[i, j]: weighted prediction of leaf j in tree i\n",
    "        # treeleaftuples: the set contains (tree i, leaf j) tuples\n",
    "        p = {}\n",
    "        treeleaftuples = []\n",
    "        for i in range(len(trees)):\n",
    "            for j in leaves(trees, i):\n",
    "                p[i,j] = sc_y.inverse_transform(np.asarray(prediction(trees,i,j,1)).reshape(-1,1)) * weight_all\n",
    "                treeleaftuples.append((i,j))\n",
    "        # treesplits: the list of splits\n",
    "        treesplits = []\n",
    "        for i in range(ntrees):\n",
    "            for s in splits(trees, i):\n",
    "                treesplits.append((i,s))\n",
    "            \n",
    "        # create a new model\n",
    "        m = gp.Model(\"tree_ensemble\")\n",
    "        m.Params.LogToConsole = 0\n",
    "        m.setParam('TimeLimit', 600)\n",
    "\n",
    "        #create variables\n",
    "        X_one = {}\n",
    "        for i in total_split_variable(trees):\n",
    "            for j in range(K(trees,i)):\n",
    "                X_one[i,j]=m.addVar(vtype=GRB.BINARY, name='X_one'+str(i)+'_'+str(j))\n",
    "        y = m.addVars(treeleaftuples, obj = p, lb = 0, name = 'y')\n",
    "        \n",
    "        # Add constraint\n",
    "        m.addConstrs((gp.quicksum(y[t,l] for l in leaves(trees, t)) == 1 for t in settrees), name = 'oney')  \n",
    "        m.addConstrs((gp.quicksum(y[t,l] for l in left_leaf(trees, t, s)) <=  X_one[V(trees,t,s),C(trees,t,s)] for t,s in treesplits), name = 'left')\n",
    "        m.addConstrs((gp.quicksum(y[t,l] for l in right_leaf(trees, t, s)) <=  1 - X_one[V(trees,t,s),C(trees,t,s)] for t,s in treesplits), name = 'right')\n",
    "        \n",
    "\n",
    "        for i in total_split_variable(trees):\n",
    "            for j in range(K(trees,i)-1):\n",
    "                m.addConstr(X_one[i,j] - X_one[i,j+1] <= 0)\n",
    "\n",
    "        m.update()\n",
    "        m.write(\"m.lp\")\n",
    "    \n",
    "        m.optimize()\n",
    "        times.append(m.Runtime)\n",
    "        objs.append(m.objVal)\n",
    "        num_binvars.append(m.NumBinVars)\n",
    "        num_constrs.append(m.NumConstrs)\n",
    "    \n",
    "    times_n[n] = times\n",
    "    objs_n[n] = objs\n",
    "    num_binvars_n[n] = num_binvars\n",
    "    num_constrs_n[n] = num_constrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d8d104-ec7c-41a5-b31e-ebb9142e173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(times_n)\n",
    "print(objs_n)\n",
    "print(num_binvars_n)\n",
    "print(num_constrs_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d60af4a-a185-4873-97d4-8b5bc12b6a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_save(path, file, filename):\n",
    "    file_loc = path + '/' + filename + '.pickle'\n",
    "    with open(file_loc, 'wb') as handle:\n",
    "        pickle.dump(file, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# create the directory to save the results\n",
    "path = './results_opt_rf'\n",
    "\n",
    "try:\n",
    "    os.mkdir(path)\n",
    "except FileExistsError:\n",
    "    print('Folder already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee8c830-7a26-48be-894f-5d40663fa363",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_save(path, objs_n, 'rf_objs_n')\n",
    "pickle_save(path, times_n, 'rf_times_n')\n",
    "pickle_save(path, num_binvars_n, 'rf_binvars_n')\n",
    "pickle_save(path, num_constrs_n, 'rf_constrs_n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
