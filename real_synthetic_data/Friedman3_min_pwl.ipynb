{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b0fa23-7059-4f9a-a88e-df74a6342e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlinsights.mlmodel import PiecewiseRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "from helpers.pwl_tree import get_coef, get_subdomain, y_min_max_calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff5163b-5927-4aa3-8b85-8236f59292b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_friedman3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a536bc-54a8-43dc-97f8-431c3e574259",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4 # max dimention of the input vector\n",
    "n_samples = 10 # number of sampled quadratic function for each dimension\n",
    "\n",
    "# set random seed\n",
    "global_seed = 777\n",
    "random.seed(global_seed)\n",
    "np.random.seed(global_seed)\n",
    "seeds = np.random.randint(1,1000,(1,n_samples))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebbb5c9-6b03-4327-bacd-4751a7325662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean value of the deterministic part of the function generating Friedman 3 dataset\n",
    "mean_val = 1.324"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed48de2-526c-4202-b985-e6271b545a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = [] # list that stores solution times\n",
    "objs = [] # list that stores obj function values\n",
    "num_binvars = [] # list that stores # binary variables\n",
    "num_constrs = [] # list that stores # constraints\n",
    "best_models = [] # list that stores the best trained model\n",
    "mapes = [] # list that stores MAPEs of the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc66fe19-d1e0-442c-942e-457f337872af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results_opt_friedman3_max_pwl/best_models.pickle', 'rb') as best_models_pickle:\n",
    "    best_models = pickle.load(best_models_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fe683c-6a4d-41ac-a418-c247ebc97709",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(n_samples)):\n",
    "    \n",
    "    # generate data using make_friedman1 function\n",
    "    # dependent variables add the mean value to enable the downstream cross dataset/method statistical tests\n",
    "    X_variable_raw, Y_variable_raw = make_friedman3(n_samples = 5000, random_state = seeds[i])\n",
    "    Y_variable_raw += mean_val\n",
    "    X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(X_variable_raw, Y_variable_raw,\n",
    "                                                                        random_state=seeds[i], test_size = 0.25)\n",
    "    \n",
    "    # scaling\n",
    "    sc_X = MinMaxScaler()\n",
    "    sc_y = MinMaxScaler()\n",
    "\n",
    "    X_variable = sc_X.fit_transform(X_train_raw)\n",
    "    Y_variable = sc_y.fit_transform(y_train_raw.reshape(-1,1))\n",
    "    Y_variable = np.squeeze(Y_variable)\n",
    "    \n",
    "    labels=np.array(Y_variable)\n",
    "    features = np.array(X_variable)\n",
    "    \n",
    "    # continue to scaling for obtain parameters for subdomains\n",
    "    dx = sc_X.data_range_\n",
    "    dy = sc_y.data_range_\n",
    "    xmin = sc_X.data_min_\n",
    "    ymin = sc_y.data_min_\n",
    "    \n",
    "    # use the model trained\n",
    "    best_tree = best_models[i]\n",
    "    best_models.append(best_tree)\n",
    "    \n",
    "    # prediction accuracy \n",
    "    y_predict = best_tree.predict(sc_X.transform(X_test_raw))\n",
    "    y_predict_inversed = sc_y.inverse_transform(y_predict.reshape(-1,1))\n",
    "    mapes.append(mean_absolute_percentage_error(y_test_raw, y_predict_inversed))\n",
    "    \n",
    "    # obtain queries corresponding to non-leaf node, as well as leaf node information\n",
    "    # revert the scaling of prediction at each leaf node\n",
    "    y_train_predict = np.transpose(sc_y.inverse_transform(best_tree.predict(X_variable).reshape(-1,1))).tolist()[0]\n",
    "    # ymin_in_bins (ymax_in_bins) contains min/max predicted y values for each leaf\n",
    "    ymin_in_bins, ymax_in_bins = y_min_max_calc(best_tree, X_variable, y_train_predict)\n",
    "    \n",
    "    # linear regression model for each leaf node\n",
    "    lincoeff = get_coef(best_tree)\n",
    "    # obtain subdomain information for each leaf node; cannot directly obtain it from the PiecewiseRegressor using this version of mlinsights;\n",
    "    # Train the decision tree to obtain the binner used by the PiecewiseRegressor\n",
    "    dctree = DecisionTreeRegressor(random_state=0,min_samples_leaf=best_tree.binner.min_samples_leaf)\n",
    "    dctree.fit(X_variable, Y_variable)\n",
    "    # obtain tree structure information\n",
    "    tree_dict, tree_params = get_subdomain(dctree, n)\n",
    "        \n",
    "    # tree_params_less: upper bound of x for a leaf\n",
    "    # tree_params_larger: lower bound of x for a leaf\n",
    "    tree_params_less = tree_params[:,:n]\n",
    "    tree_params_larger = tree_params[:,n:]\n",
    "    # number of leaves\n",
    "    n_leaves = best_tree.n_estimators_\n",
    "    \n",
    "    # inverse transform coefficients and intercepts of linear regressors of each leaf\n",
    "    lincoeff_coeffs_raw = lincoeff[:,:-1]\n",
    "    lincoeff_intecept_raw = lincoeff[:,-1]\n",
    "        \n",
    "    lincoeff_coeffs = lincoeff_coeffs_raw\n",
    "    lincoeff_intecept = lincoeff_intecept_raw\n",
    "    \n",
    "    lincoeff_coeffs = lincoeff_coeffs_raw * dy\n",
    "    lincoeff_coeffs = np.divide(lincoeff_coeffs,dx)\n",
    "    lincoeff_intecept = lincoeff_intecept_raw - np.sum(np.divide(np.multiply(lincoeff_coeffs_raw, xmin), dx), axis=1)\n",
    "    lincoeff_intecept *= dy\n",
    "    lincoeff_intecept += ymin\n",
    "    \n",
    "    # revert scaling of tree params\n",
    "    tree_params_less = sc_X.inverse_transform(tree_params_less)\n",
    "    tree_params_larger = sc_X.inverse_transform(tree_params_larger)\n",
    "\n",
    "    # set generation\n",
    "    # set for each input variable dimension\n",
    "    rangen = range(n)\n",
    "    # set for leaf nodes\n",
    "    rangen_leaves = range(n_leaves)\n",
    "    # (u, m) tuple in the paper\n",
    "    rangeleaven = []\n",
    "    for i in rangen:\n",
    "        for j in rangen_leaves:\n",
    "            rangeleaven.append((i,j))\n",
    "    # set containing (m, k) tuple for constraints for truncation\n",
    "    rangemk = []\n",
    "    rangek = range(3)\n",
    "    for i in rangen_leaves:\n",
    "        for j in rangek:\n",
    "            rangemk.append((i,j))\n",
    "            \n",
    "    #create a new model\n",
    "    m = gp.Model(\"PWL\")\n",
    "    m.Params.LogToConsole = 0\n",
    "    m.setParam('TimeLimit', 60)\n",
    "\n",
    "    # create variables\n",
    "    # binary variable Z_m\n",
    "    z = m.addVars(rangen_leaves, name = 'z', vtype = GRB.BINARY)\n",
    "    # independent variable X_u\n",
    "    x = m.addVars(rangen, ub = [100, 280*2*math.pi, 1, 11], lb = [0, 20*2*math.pi, 0, 1], name = 'x')\n",
    "    # disaggregate variable \\bar{X}_{u, m}\n",
    "    x_bar = m.addVars(rangeleaven, name = 'x_bar')\n",
    "    # disaggregate variable \\bar{Y}_m\n",
    "    y_bar = m.addVars(rangen_leaves, name = 'y_bar', lb = -10)\n",
    "    # dependent variable Y\n",
    "    y = m.addVar(obj = 1, name = 'y', lb = -10)\n",
    "    # disaggregate variable \\tilde{Y}_{m, k}\n",
    "    y_tilde = m.addVars(rangemk, name = 'y_tilde', lb = -10)\n",
    "    # binary disaggregate variable \\bar{Z}_{m, k}\n",
    "    w = m.addVars(rangemk, name = 'w', vtype = GRB.BINARY)\n",
    "    # disaggregate variable \\hat{Y}\n",
    "    y_hat = m.addVars(rangen_leaves, name = 'y_hat', lb = -10)\n",
    "    \n",
    "    # obj\n",
    "    m.setObjective(y, GRB.MINIMIZE)\n",
    "\n",
    "    # Add constraint\n",
    "    # Constraint 3B-1\n",
    "    m.addConstr((gp.quicksum(z[l] for l in rangen_leaves) == 1), name = 'onez')\n",
    "        \n",
    "    # Constraint 3B-2\n",
    "    m.addConstrs((tree_params_larger[l][k] * z[l] <= x_bar[k,l] for k,l in rangeleaven), name = 'largerthan')\n",
    "    m.addConstrs((tree_params_less[l][k] * z[l] >= x_bar[k,l] for k,l in rangeleaven), name = 'lessthan')\n",
    "        \n",
    "    # Constraint 3B-3\n",
    "    m.addConstrs((gp.quicksum(x_bar[k,l] for l in rangen_leaves) == x[k] for k in rangen), name = 'calcx') \n",
    "        \n",
    "    # Constraint 3B-4\n",
    "    m.addConstr((gp.quicksum(y_bar[l] for l in rangen_leaves) == y), name = 'calcy')\n",
    "        \n",
    "    # Constraint 3B-5\n",
    "    m.addConstrs((gp.quicksum(lincoeff_coeffs[l][k] * x_bar[k,l] for k in rangen) + lincoeff_intecept[l] * z[l] == y_hat[l] \\\n",
    "                  for l in rangen_leaves), name = 'calcy_hat')\n",
    "        \n",
    "    # Constraint 3B-6\n",
    "    m.addConstrs((y_bar[l] == ymax_in_bins[l] * w[l,0] + y_tilde[l, 1] + ymax_in_bins[l] * w[l,2] for l in rangen_leaves),\n",
    "                     name = 'calcy_bar')\n",
    "        \n",
    "    # Constraint 3B-7\n",
    "    m.addConstrs((gp.quicksum(y_tilde[l,k] for k in rangek) == y_hat[l] for l in rangen_leaves), name = 'calcy_hat1')\n",
    "        \n",
    "    # Constraint 3B-8\n",
    "    m.addConstrs((gp.quicksum(w[l,k] for k in rangek) == z[l] for l in rangen_leaves), name = 'calcw')\n",
    "        \n",
    "    # Constraint 3B-9\n",
    "    m.addConstrs((y_tilde[l, 0] <= ymin_in_bins[l] * w[l,0] for l in rangen_leaves), name = 'calcy_tilde0')\n",
    "        \n",
    "    # Constraint 3B-10\n",
    "    m.addConstrs((y_tilde[l, 1] >= ymin_in_bins[l] * w[l,1] for l in rangen_leaves), name = 'calcy_tilde1')\n",
    "    m.addConstrs((y_tilde[l, 1] <= ymax_in_bins[l] * w[l,1] for l in rangen_leaves), name = 'calcy_tilde11')\n",
    "        \n",
    "    # Constraint 3B-11\n",
    "    m.addConstrs((y_tilde[l, 2] >= ymax_in_bins[l] * w[l,2] for l in rangen_leaves), name = 'calcy_tilde2')\n",
    "    \n",
    "    m.update()\n",
    "    m.write(\"m.lp\")\n",
    "    \n",
    "    m.optimize()\n",
    "    \n",
    "    times.append(m.Runtime)\n",
    "    objs.append(m.objVal)\n",
    "    num_binvars.append(m.NumBinVars)\n",
    "    num_constrs.append(m.NumConstrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517352ba-e345-421c-b50b-43d3f9090b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(times)\n",
    "print(objs)\n",
    "print(num_binvars)\n",
    "print(num_constrs)\n",
    "print(mapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48d084c-9524-4792-8cf5-ec80e03fb7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_save(path, file, filename):\n",
    "    file_loc = path + '/' + filename + '.pickle'\n",
    "    with open(file_loc, 'wb') as handle:\n",
    "        pickle.dump(file, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# create the directory to save the results\n",
    "path = './results_opt_friedman3_min_pwl'\n",
    "\n",
    "try:\n",
    "    os.mkdir(path)\n",
    "except FileExistsError:\n",
    "    print('Folder already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f91283-8975-4b55-aaf9-02cd2fc7f0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_save(path, objs, 'objs')\n",
    "pickle_save(path, times, 'times')\n",
    "pickle_save(path, num_binvars, 'num_binvars')\n",
    "pickle_save(path, num_constrs, 'num_constrs')\n",
    "pickle_save(path, best_models, 'best_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfbb45f-fb0c-4c64-8559-b392a2f217ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
