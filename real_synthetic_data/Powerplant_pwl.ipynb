{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9922f4fa-66ac-4e12-b8e6-22c0354d04af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlinsights.mlmodel import PiecewiseRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "from helpers.pwl_tree import get_coef, get_subdomain, y_min_max_calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05208368-fae1-4343-a36f-461fff88f0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4 # max dimention of the input vector\n",
    "n_samples = 10 # number of sampled quadratic function for each dimension\n",
    "\n",
    "# set random seed\n",
    "global_seed = 777\n",
    "random.seed(global_seed)\n",
    "np.random.seed(global_seed)\n",
    "seeds = np.random.randint(1,1000,(1,n_samples))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2911cb-380f-4cf3-b91b-06176456fad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = [] # list that stores solution times\n",
    "objs = [] # list that stores obj function values\n",
    "num_binvars = [] # list that stores # binary variables\n",
    "num_constrs = [] # list that stores # constraints\n",
    "best_models = [] # list that stores the best trained model\n",
    "mapes = [] # list that stores MAPEs of the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc9da2e-adf7-4f41-bb93-f890756222d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(n_samples)):\n",
    "    \n",
    "    # read data from csv file\n",
    "    file_name = './power_plant.csv'\n",
    "    df = pd.read_csv(file_name)\n",
    "    \n",
    "    X_variable_raw = df.iloc[:,:-1].values\n",
    "    Y_variable_raw = df.iloc[:,-1].values\n",
    "    X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(X_variable_raw, Y_variable_raw,\n",
    "                                                                        random_state=seeds[i], test_size = 0.25)\n",
    "    \n",
    "    # scaling\n",
    "    sc_X = MinMaxScaler()\n",
    "    sc_y = MinMaxScaler()\n",
    "\n",
    "    X_variable = sc_X.fit_transform(X_train_raw)\n",
    "    Y_variable = sc_y.fit_transform(y_train_raw.reshape(-1,1))\n",
    "    Y_variable = np.squeeze(Y_variable)\n",
    "    \n",
    "    labels=np.array(Y_variable)\n",
    "    features = np.array(X_variable)\n",
    "    \n",
    "    # continue to scaling for obtain parameters for subdomains\n",
    "    dx = sc_X.data_range_\n",
    "    dy = sc_y.data_range_\n",
    "    xmin = sc_X.data_min_\n",
    "    ymin = sc_y.data_min_\n",
    "    \n",
    "    #training\n",
    "    #PWL trees\n",
    "    random.seed(seeds[i])\n",
    "    np.random.seed(seeds[i])\n",
    "    gs0 = GridSearchCV(PiecewiseRegressor(verbose=False, estimator = LinearRegression()),\n",
    "\t\t\t\t  param_grid = {'binner': [DecisionTreeRegressor(min_samples_leaf=i, random_state=0) for i in range(5, 10*n+1, 5)]},\n",
    "\t\t\t\t  return_train_score = True, cv = 5,\n",
    "\t\t\t\t  scoring = 'neg_mean_squared_error')\n",
    "    gs0.fit(X_variable, Y_variable)\n",
    "    best_tree = gs0.best_estimator_\n",
    "    best_models.append(best_tree)\n",
    "    \n",
    "    # prediction accuracy \n",
    "    y_predict = best_tree.predict(sc_X.transform(X_test_raw))\n",
    "    y_predict_inversed = sc_y.inverse_transform(y_predict.reshape(-1,1))\n",
    "    mapes.append(mean_absolute_percentage_error(y_test_raw, y_predict_inversed))\n",
    "    \n",
    "    # obtain queries corresponding to non-leaf node, as well as leaf node information\n",
    "    # revert the scaling of prediction at each leaf node\n",
    "    y_train_predict = np.transpose(sc_y.inverse_transform(best_tree.predict(X_variable).reshape(-1,1))).tolist()[0]\n",
    "    # ymin_in_bins (ymax_in_bins) contains min/max predicted y values for each leaf\n",
    "    ymin_in_bins, ymax_in_bins = y_min_max_calc(best_tree, X_variable, y_train_predict)\n",
    "    \n",
    "    # linear regression model for each leaf node\n",
    "    lincoeff = get_coef(best_tree)\n",
    "    # obtain subdomain information for each leaf node; cannot directly obtain it from the PiecewiseRegressor using this version of mlinsights;\n",
    "    # Train the decision tree to obtain the binner used by the PiecewiseRegressor\n",
    "    dctree = DecisionTreeRegressor(random_state=0,min_samples_leaf=best_tree.binner.min_samples_leaf)\n",
    "    dctree.fit(X_variable, Y_variable)\n",
    "    # obtain tree structure information\n",
    "    tree_dict, tree_params = get_subdomain(dctree, n)\n",
    "        \n",
    "    # tree_params_less: upper bound of x for a leaf\n",
    "    # tree_params_larger: lower bound of x for a leaf\n",
    "    tree_params_less = tree_params[:,:n]\n",
    "    tree_params_larger = tree_params[:,n:]\n",
    "    # number of leaves\n",
    "    n_leaves = best_tree.n_estimators_\n",
    "    \n",
    "    # inverse transform coefficients and intercepts of linear regressors of each leaf\n",
    "    lincoeff_coeffs_raw = lincoeff[:,:-1]\n",
    "    lincoeff_intecept_raw = lincoeff[:,-1]\n",
    "        \n",
    "    lincoeff_coeffs = lincoeff_coeffs_raw\n",
    "    lincoeff_intecept = lincoeff_intecept_raw\n",
    "    \n",
    "    lincoeff_coeffs = lincoeff_coeffs_raw * dy\n",
    "    lincoeff_coeffs = np.divide(lincoeff_coeffs,dx)\n",
    "    lincoeff_intecept = lincoeff_intecept_raw - np.sum(np.divide(np.multiply(lincoeff_coeffs_raw, xmin), dx), axis=1)\n",
    "    lincoeff_intecept *= dy\n",
    "    lincoeff_intecept += ymin\n",
    "    \n",
    "    # revert scaling of tree params\n",
    "    tree_params_less = sc_X.inverse_transform(tree_params_less)\n",
    "    tree_params_larger = sc_X.inverse_transform(tree_params_larger)\n",
    "\n",
    "    # set generation\n",
    "    # set for each input variable dimension\n",
    "    rangen = range(n)\n",
    "    # set for leaf nodes\n",
    "    rangen_leaves = range(n_leaves)\n",
    "    # (u, m) tuple in the paper\n",
    "    rangeleaven = []\n",
    "    for i in rangen:\n",
    "        for j in rangen_leaves:\n",
    "            rangeleaven.append((i,j))\n",
    "    # set containing (m, k) tuple for constraints for truncation\n",
    "    rangemk = []\n",
    "    rangek = range(3)\n",
    "    for i in rangen_leaves:\n",
    "        for j in rangek:\n",
    "            rangemk.append((i,j))\n",
    "            \n",
    "    #create a new model\n",
    "    m = gp.Model(\"PWL\")\n",
    "    m.Params.LogToConsole = 0\n",
    "    m.setParam('TimeLimit', 60)\n",
    "\n",
    "    # create variables\n",
    "    # binary variable Z_m\n",
    "    z = m.addVars(rangen_leaves, name = 'z', vtype = GRB.BINARY)\n",
    "    # independent variable X_u\n",
    "    x = m.addVars(rangen, ub = np.amax(X_variable_raw, axis = 0).tolist(), lb = np.amin(X_variable_raw, axis = 0).tolist(), name = 'x')\n",
    "    # disaggregate variable \\bar{X}_{u, m}\n",
    "    x_bar = m.addVars(rangeleaven, name = 'x_bar')\n",
    "    # disaggregate variable \\bar{Y}_m\n",
    "    y_bar = m.addVars(rangen_leaves, name = 'y_bar')\n",
    "    # dependent variable Y\n",
    "    y = m.addVar(obj = 1, name = 'y')\n",
    "    # disaggregate variable \\tilde{Y}_{m, k}\n",
    "    y_tilde = m.addVars(rangemk, name = 'y_tilde', lb = -10)\n",
    "    # binary disaggregate variable \\bar{Z}_{m, k}\n",
    "    w = m.addVars(rangemk, name = 'w', vtype = GRB.BINARY)\n",
    "    # disaggregate variable \\hat{Y}\n",
    "    y_hat = m.addVars(rangen_leaves, name = 'y_hat', lb = -10)\n",
    "    \n",
    "    # obj\n",
    "    m.setObjective(y, GRB.MAXIMIZE)\n",
    "\n",
    "    # Add constraint\n",
    "    # Constraint 3B-1\n",
    "    m.addConstr((gp.quicksum(z[l] for l in rangen_leaves) == 1), name = 'onez')\n",
    "        \n",
    "    # Constraint 3B-2\n",
    "    m.addConstrs((tree_params_larger[l][k] * z[l] <= x_bar[k,l] for k,l in rangeleaven), name = 'largerthan')\n",
    "    m.addConstrs((tree_params_less[l][k] * z[l] >= x_bar[k,l] for k,l in rangeleaven), name = 'lessthan')\n",
    "        \n",
    "    # Constraint 3B-3\n",
    "    m.addConstrs((gp.quicksum(x_bar[k,l] for l in rangen_leaves) == x[k] for k in rangen), name = 'calcx') \n",
    "        \n",
    "    # Constraint 3B-4\n",
    "    m.addConstr((gp.quicksum(y_bar[l] for l in rangen_leaves) == y), name = 'calcy')\n",
    "        \n",
    "    # Constraint 3B-5\n",
    "    m.addConstrs((gp.quicksum(lincoeff_coeffs[l][k] * x_bar[k,l] for k in rangen) + lincoeff_intecept[l] * z[l] == y_hat[l] \\\n",
    "                  for l in rangen_leaves), name = 'calcy_hat')\n",
    "        \n",
    "    # Constraint 3B-6\n",
    "    m.addConstrs((y_bar[l] == ymax_in_bins[l] * w[l,0] + y_tilde[l, 1] + ymax_in_bins[l] * w[l,2] for l in rangen_leaves),\n",
    "                     name = 'calcy_bar')\n",
    "        \n",
    "    # Constraint 3B-7\n",
    "    m.addConstrs((gp.quicksum(y_tilde[l,k] for k in rangek) == y_hat[l] for l in rangen_leaves), name = 'calcy_hat1')\n",
    "        \n",
    "    # Constraint 3B-8\n",
    "    m.addConstrs((gp.quicksum(w[l,k] for k in rangek) == z[l] for l in rangen_leaves), name = 'calcw')\n",
    "        \n",
    "    # Constraint 3B-9\n",
    "    m.addConstrs((y_tilde[l, 0] <= ymin_in_bins[l] * w[l,0] for l in rangen_leaves), name = 'calcy_tilde0')\n",
    "        \n",
    "    # Constraint 3B-10\n",
    "    m.addConstrs((y_tilde[l, 1] >= ymin_in_bins[l] * w[l,1] for l in rangen_leaves), name = 'calcy_tilde1')\n",
    "    m.addConstrs((y_tilde[l, 1] <= ymax_in_bins[l] * w[l,1] for l in rangen_leaves), name = 'calcy_tilde11')\n",
    "        \n",
    "    # Constraint 3B-11\n",
    "    m.addConstrs((y_tilde[l, 2] >= ymax_in_bins[l] * w[l,2] for l in rangen_leaves), name = 'calcy_tilde2')\n",
    "    \n",
    "    m.update()\n",
    "    m.write(\"m.lp\")\n",
    "    \n",
    "    m.optimize()\n",
    "    \n",
    "    times.append(m.Runtime)\n",
    "    objs.append(m.objVal)\n",
    "    num_binvars.append(m.NumBinVars)\n",
    "    num_constrs.append(m.NumConstrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465e1a2d-7941-41ac-bad3-d140abeadffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(times)\n",
    "print(objs)\n",
    "print(num_binvars)\n",
    "print(num_constrs)\n",
    "print(mapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5a63c3-cb4d-43dd-8e9c-a578920819c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_save(path, file, filename):\n",
    "    file_loc = path + '/' + filename + '.pickle'\n",
    "    with open(file_loc, 'wb') as handle:\n",
    "        pickle.dump(file, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# create the directory to save the results\n",
    "path = './results_opt_powerplant_pwl'\n",
    "\n",
    "try:\n",
    "    os.mkdir(path)\n",
    "except FileExistsError:\n",
    "    print('Folder already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc4501b-0fa1-4ee2-bdfa-0462491b8da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_save(path, objs, 'objs')\n",
    "pickle_save(path, times, 'times')\n",
    "pickle_save(path, num_binvars, 'num_binvars')\n",
    "pickle_save(path, num_constrs, 'num_constrs')\n",
    "pickle_save(path, mapes, 'mapes')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
